{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_files = glob.glob(os.path.join(destination_path_vc, \"investments_VC.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import chardet\n",
    "# with open(all_files[0], 'rb') as rawdata:\n",
    "#     result = chardet.detect(rawdata.read(100000))\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the files into dataframes\n",
    "# dfs = [pd.read_csv(f,encoding=\"ISO-8859-1\") for f in all_files]\n",
    "\n",
    "# # Combine the list of dataframes\n",
    "# df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vc = pd.read_csv(os.path.join(destination_path_vc, \"investments_VC.csv\"),encoding=\"ISO-8859-1\")\n",
    "df_gdp = pd.read_csv(os.path.join(destination_path_gdp, \"Life Expectancy vs GDP 1950-2018.csv\"),encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permalink</th>\n",
       "      <th>name</th>\n",
       "      <th>homepage_url</th>\n",
       "      <th>category_list</th>\n",
       "      <th>market</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>status</th>\n",
       "      <th>country_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_market</th>\n",
       "      <th>product_crowdfunding</th>\n",
       "      <th>round_A</th>\n",
       "      <th>round_B</th>\n",
       "      <th>round_C</th>\n",
       "      <th>round_D</th>\n",
       "      <th>round_E</th>\n",
       "      <th>round_F</th>\n",
       "      <th>round_G</th>\n",
       "      <th>round_H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/organization/waywire</td>\n",
       "      <td>#waywire</td>\n",
       "      <td>http://www.waywire.com</td>\n",
       "      <td>|Entertainment|Politics|Social Media|News|</td>\n",
       "      <td>News</td>\n",
       "      <td>17,50,000</td>\n",
       "      <td>acquired</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York City</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/organization/tv-communications</td>\n",
       "      <td>&amp;TV Communications</td>\n",
       "      <td>http://enjoyandtv.com</td>\n",
       "      <td>|Games|</td>\n",
       "      <td>Games</td>\n",
       "      <td>40,00,000</td>\n",
       "      <td>operating</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/organization/rock-your-paper</td>\n",
       "      <td>'Rock' Your Paper</td>\n",
       "      <td>http://www.rockyourpaper.org</td>\n",
       "      <td>|Publishing|Education|</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>40,000</td>\n",
       "      <td>operating</td>\n",
       "      <td>EST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tallinn</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/organization/in-touch-network</td>\n",
       "      <td>(In)Touch Network</td>\n",
       "      <td>http://www.InTouchNetwork.com</td>\n",
       "      <td>|Electronics|Guides|Coffee|Restaurants|Music|i...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>15,00,000</td>\n",
       "      <td>operating</td>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/organization/r-ranch-and-mine</td>\n",
       "      <td>-R- Ranch and Mine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>|Tourism|Entertainment|Games|</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>60,000</td>\n",
       "      <td>operating</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         permalink                name  \\\n",
       "0            /organization/waywire            #waywire   \n",
       "1  /organization/tv-communications  &TV Communications   \n",
       "2    /organization/rock-your-paper   'Rock' Your Paper   \n",
       "3   /organization/in-touch-network   (In)Touch Network   \n",
       "4   /organization/r-ranch-and-mine  -R- Ranch and Mine   \n",
       "\n",
       "                    homepage_url  \\\n",
       "0         http://www.waywire.com   \n",
       "1          http://enjoyandtv.com   \n",
       "2   http://www.rockyourpaper.org   \n",
       "3  http://www.InTouchNetwork.com   \n",
       "4                            NaN   \n",
       "\n",
       "                                       category_list        market   \\\n",
       "0         |Entertainment|Politics|Social Media|News|          News    \n",
       "1                                            |Games|         Games    \n",
       "2                             |Publishing|Education|    Publishing    \n",
       "3  |Electronics|Guides|Coffee|Restaurants|Music|i...   Electronics    \n",
       "4                      |Tourism|Entertainment|Games|       Tourism    \n",
       "\n",
       "   funding_total_usd      status country_code state_code         region  ...  \\\n",
       "0          17,50,000    acquired          USA         NY  New York City  ...   \n",
       "1          40,00,000   operating          USA         CA    Los Angeles  ...   \n",
       "2             40,000   operating          EST        NaN        Tallinn  ...   \n",
       "3          15,00,000   operating          GBR        NaN         London  ...   \n",
       "4             60,000   operating          USA         TX         Dallas  ...   \n",
       "\n",
       "  secondary_market  product_crowdfunding round_A round_B round_C  round_D  \\\n",
       "0              0.0                   0.0     0.0     0.0     0.0      0.0   \n",
       "1              0.0                   0.0     0.0     0.0     0.0      0.0   \n",
       "2              0.0                   0.0     0.0     0.0     0.0      0.0   \n",
       "3              0.0                   0.0     0.0     0.0     0.0      0.0   \n",
       "4              0.0                   0.0     0.0     0.0     0.0      0.0   \n",
       "\n",
       "  round_E round_F  round_G  round_H  \n",
       "0     0.0     0.0      0.0      0.0  \n",
       "1     0.0     0.0      0.0      0.0  \n",
       "2     0.0     0.0      0.0      0.0  \n",
       "3     0.0     0.0      0.0      0.0  \n",
       "4     0.0     0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'EST', 'GBR', 'ARG', nan, 'HKG', 'CHL', 'DEU', 'FRA', 'CHN',\n",
       "       'CAN', 'AUS', 'ROM', 'NLD', 'SWE', 'RUS', 'DNK', 'IND', 'SGP',\n",
       "       'NOR', 'BEL', 'IRL', 'ITA', 'ISR', 'ESP', 'THA', 'NZL', 'CZE',\n",
       "       'CHE', 'BRA', 'HUN', 'JPN', 'BWA', 'KOR', 'NGA', 'FIN', 'TUR',\n",
       "       'CRI', 'PRT', 'TWN', 'KHM', 'COL', 'UKR', 'LTU', 'ZAF', 'AUT',\n",
       "       'PHL', 'ISL', 'BGR', 'URY', 'HRV', 'KEN', 'MEX', 'JOR', 'VNM',\n",
       "       'GHA', 'PER', 'POL', 'IDN', 'PAN', 'LVA', 'ALB', 'UGA', 'LBN',\n",
       "       'GRC', 'ARE', 'PAK', 'EGY', 'SVK', 'LUX', 'MYS', 'BHS', 'ARM',\n",
       "       'DZA', 'MDA', 'TUN', 'NIC', 'TZA', 'CYP', 'NPL', 'BHR', 'CMR',\n",
       "       'SRB', 'SAU', 'CYM', 'BRN', 'SLV', 'ECU', 'MLT', 'SVN', 'LAO',\n",
       "       'TTO', 'MAR', 'MMR', 'BGD', 'DOM', 'BMU', 'LIE', 'MOZ', 'GTM',\n",
       "       'AZE', 'MCO', 'ZWE', 'UZB', 'OMN', 'BLR', 'JEY', 'JAM', 'KWT',\n",
       "       'MUS', 'CIV', 'SOM', 'MKD', 'GIB', 'SYC', 'MAF'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vc.country_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Population (historical estimates)</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1950</td>\n",
       "      <td>27.638</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>7752117.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1951</td>\n",
       "      <td>27.878</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>7840151.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>28.361</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>7935996.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1953</td>\n",
       "      <td>28.852</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>8039684.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1954</td>\n",
       "      <td>29.350</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>8151316.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Year  Life expectancy  GDP per capita  \\\n",
       "0  Afghanistan  1950           27.638          1156.0   \n",
       "1  Afghanistan  1951           27.878          1170.0   \n",
       "2  Afghanistan  1952           28.361          1189.0   \n",
       "3  Afghanistan  1953           28.852          1240.0   \n",
       "4  Afghanistan  1954           29.350          1245.0   \n",
       "\n",
       "   Population (historical estimates) Continent  \n",
       "0                          7752117.0      Asia  \n",
       "1                          7840151.0      Asia  \n",
       "2                          7935996.0      Asia  \n",
       "3                          8039684.0      Asia  \n",
       "4                          8151316.0      Asia  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Asia', 'Europe', 'Africa', 'Oceania', 'North America',\n",
       "       'South America'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gdp.Continent.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('https://query.data.world/s/qoe7sye64wcaydmefdymxwnbyg6fnh?dws=00000',sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'varShort', 'varLong', 'Map'], dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs_urban=[]\n",
    "for i in range(7):\n",
    "    dfs_urban.append(pd.read_excel('https://query.data.world/s/qoe7sye64wcaydmefdymxwnbyg6fnh?dws=00000',sheet_name=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPStxt</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>RuralUrbanContinuumCode2013</th>\n",
       "      <th>UrbanInfluenceCode2013</th>\n",
       "      <th>RuralUrbanContinuumCode2003</th>\n",
       "      <th>UrbanInfluenceCode2003</th>\n",
       "      <th>Metro2013</th>\n",
       "      <th>Nonmetro2013</th>\n",
       "      <th>Micropolitan2013</th>\n",
       "      <th>...</th>\n",
       "      <th>LowEducation2000</th>\n",
       "      <th>HiOutMigration2008</th>\n",
       "      <th>Noncore2013</th>\n",
       "      <th>NonmetroNotAdj2003</th>\n",
       "      <th>NonmetroAdj2003</th>\n",
       "      <th>Noncore2003</th>\n",
       "      <th>Micropolitan2003</th>\n",
       "      <th>Nonmetro2003</th>\n",
       "      <th>Metro2003</th>\n",
       "      <th>PersistentPoverty2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>AL</td>\n",
       "      <td>Blount</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>72145</td>\n",
       "      <td>PR</td>\n",
       "      <td>Vega Baja</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>72147</td>\n",
       "      <td>PR</td>\n",
       "      <td>Vieques</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>72149</td>\n",
       "      <td>PR</td>\n",
       "      <td>Villalba</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>72151</td>\n",
       "      <td>PR</td>\n",
       "      <td>Yabucoa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>72153</td>\n",
       "      <td>PR</td>\n",
       "      <td>Yauco</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3225 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPStxt State     County  RuralUrbanContinuumCode2013  \\\n",
       "0        1001    AL    Autauga                          2.0   \n",
       "1        1003    AL    Baldwin                          3.0   \n",
       "2        1005    AL    Barbour                          6.0   \n",
       "3        1007    AL       Bibb                          1.0   \n",
       "4        1009    AL     Blount                          1.0   \n",
       "...       ...   ...        ...                          ...   \n",
       "3220    72145    PR  Vega Baja                          1.0   \n",
       "3221    72147    PR    Vieques                          7.0   \n",
       "3222    72149    PR   Villalba                          2.0   \n",
       "3223    72151    PR    Yabucoa                          1.0   \n",
       "3224    72153    PR      Yauco                          2.0   \n",
       "\n",
       "      UrbanInfluenceCode2013  RuralUrbanContinuumCode2003  \\\n",
       "0                        2.0                          2.0   \n",
       "1                        2.0                          4.0   \n",
       "2                        6.0                          6.0   \n",
       "3                        1.0                          1.0   \n",
       "4                        1.0                          1.0   \n",
       "...                      ...                          ...   \n",
       "3220                     1.0                          1.0   \n",
       "3221                    12.0                          7.0   \n",
       "3222                     2.0                          2.0   \n",
       "3223                     1.0                          1.0   \n",
       "3224                     2.0                          3.0   \n",
       "\n",
       "      UrbanInfluenceCode2003  Metro2013  Nonmetro2013  Micropolitan2013  ...  \\\n",
       "0                        2.0        1.0           0.0               0.0  ...   \n",
       "1                        5.0        1.0           0.0               0.0  ...   \n",
       "2                        6.0        0.0           1.0               0.0  ...   \n",
       "3                        1.0        1.0           0.0               0.0  ...   \n",
       "4                        1.0        1.0           0.0               0.0  ...   \n",
       "...                      ...        ...           ...               ...  ...   \n",
       "3220                     1.0        1.0           0.0               0.0  ...   \n",
       "3221                    12.0        0.0           1.0               0.0  ...   \n",
       "3222                     2.0        1.0           0.0               0.0  ...   \n",
       "3223                     1.0        1.0           0.0               0.0  ...   \n",
       "3224                     2.0        1.0           0.0               0.0  ...   \n",
       "\n",
       "      LowEducation2000  HiOutMigration2008  Noncore2013  NonmetroNotAdj2003  \\\n",
       "0                  0.0                 0.0          0.0                 0.0   \n",
       "1                  0.0                 0.0          0.0                 0.0   \n",
       "2                  1.0                 0.0          1.0                 0.0   \n",
       "3                  1.0                 0.0          0.0                 0.0   \n",
       "4                  0.0                 0.0          0.0                 0.0   \n",
       "...                ...                 ...          ...                 ...   \n",
       "3220               NaN                 0.0          0.0                 0.0   \n",
       "3221               NaN                 0.0          1.0                 1.0   \n",
       "3222               NaN                 0.0          0.0                 0.0   \n",
       "3223               NaN                 0.0          0.0                 0.0   \n",
       "3224               NaN                 0.0          0.0                 0.0   \n",
       "\n",
       "      NonmetroAdj2003  Noncore2003  Micropolitan2003  Nonmetro2003  Metro2003  \\\n",
       "0                 0.0          0.0               0.0           0.0        1.0   \n",
       "1                 1.0          0.0               1.0           1.0        0.0   \n",
       "2                 1.0          1.0               0.0           1.0        0.0   \n",
       "3                 0.0          0.0               0.0           0.0        1.0   \n",
       "4                 0.0          0.0               0.0           0.0        1.0   \n",
       "...               ...          ...               ...           ...        ...   \n",
       "3220              0.0          0.0               0.0           0.0        1.0   \n",
       "3221              0.0          1.0               0.0           1.0        0.0   \n",
       "3222              0.0          0.0               0.0           0.0        1.0   \n",
       "3223              0.0          0.0               0.0           0.0        1.0   \n",
       "3224              0.0          0.0               0.0           0.0        1.0   \n",
       "\n",
       "      PersistentPoverty2000  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       1.0  \n",
       "3                       1.0  \n",
       "4                       0.0  \n",
       "...                     ...  \n",
       "3220                    NaN  \n",
       "3221                    NaN  \n",
       "3222                    NaN  \n",
       "3223                    NaN  \n",
       "3224                    NaN  \n",
       "\n",
       "[3225 rows x 32 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_urban[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>varShort</th>\n",
       "      <th>varLong</th>\n",
       "      <th>Map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>County Classifications</td>\n",
       "      <td>LowEducation2000</td>\n",
       "      <td>Low education, 2000</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Category          varShort              varLong Map\n",
       "146  County Classifications  LowEducation2000  Low education, 2000   y"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_urban[1][dfs_urban[1]['varShort']==\"LowEducation2000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/sergejnuss/united-states-cities-database  no urban density available\n",
    "https://www.kaggle.com/datasets/claygendron/us-household-income-by-zip-code-2021-2011\n",
    "https://www.kaggle.com/datasets/danielbethell/adult-incomes-in-the-united-states?select=adult.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://population.un.org/wup/Download/Files/WUP2018-F01-Total_Urban_Rural.xls   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/ramjasmaurya/unicorn-startups    2007-2022\n",
    "\n",
    "https://api.census.gov/data/2023/acs/acs1/subject?get=group(S1501)&ucgid=0100000US\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ea = pd.read_excel('https://query.data.world/s/flhwzvova4hwvxlsaraeblo3ra3hhe?dws=00000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_id</th>\n",
       "      <th>ind_definition</th>\n",
       "      <th>reportyear</th>\n",
       "      <th>race_eth_code</th>\n",
       "      <th>race_eth_name</th>\n",
       "      <th>geotype</th>\n",
       "      <th>geotypevalue</th>\n",
       "      <th>geoname</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>...</th>\n",
       "      <th>numerator</th>\n",
       "      <th>denominator</th>\n",
       "      <th>estimate</th>\n",
       "      <th>LL_95CI</th>\n",
       "      <th>UL_95CI</th>\n",
       "      <th>SE</th>\n",
       "      <th>RSE</th>\n",
       "      <th>CA_decile</th>\n",
       "      <th>CA_RR</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355</td>\n",
       "      <td>Percent of population age 25 and up with a fou...</td>\n",
       "      <td>2000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AfricanAm</td>\n",
       "      <td>CA</td>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>224727.0</td>\n",
       "      <td>1302388.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tue Jun 12 12:05:41 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>355</td>\n",
       "      <td>Percent of population age 25 and up with a fou...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AIAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15746.0</td>\n",
       "      <td>113984.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tue Jun 12 12:05:41 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>355</td>\n",
       "      <td>Percent of population age 25 and up with a fou...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>CA</td>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1008647.0</td>\n",
       "      <td>2415154.0</td>\n",
       "      <td>41.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tue Jun 12 12:05:41 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355</td>\n",
       "      <td>Percent of population age 25 and up with a fou...</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Latino</td>\n",
       "      <td>CA</td>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>425972.0</td>\n",
       "      <td>5500767.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tue Jun 12 12:05:41 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>Percent of population age 25 and up with a fou...</td>\n",
       "      <td>2000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>CA</td>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>133828.0</td>\n",
       "      <td>499849.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tue Jun 12 12:05:41 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind_id                                     ind_definition reportyear  \\\n",
       "0     355  Percent of population age 25 and up with a fou...       2000   \n",
       "1     355  Percent of population age 25 and up with a fou...       2000   \n",
       "2     355  Percent of population age 25 and up with a fou...       2000   \n",
       "3     355  Percent of population age 25 and up with a fou...       2000   \n",
       "4     355  Percent of population age 25 and up with a fou...       2000   \n",
       "\n",
       "   race_eth_code race_eth_name geotype  geotypevalue     geoname county_name  \\\n",
       "0            3.0     AfricanAm      CA             6  California         NaN   \n",
       "1            1.0          AIAN      CA             6  California         NaN   \n",
       "2            2.0         Asian      CA             6  California         NaN   \n",
       "3            4.0        Latino      CA             6  California         NaN   \n",
       "4            7.0      Multiple      CA             6  California         NaN   \n",
       "\n",
       "   county_fips  ...  numerator  denominator  estimate LL_95CI  UL_95CI  SE  \\\n",
       "0          NaN  ...   224727.0    1302388.0      17.3     NaN      NaN NaN   \n",
       "1          NaN  ...    15746.0     113984.0      13.8     NaN      NaN NaN   \n",
       "2          NaN  ...  1008647.0    2415154.0      41.8     NaN      NaN NaN   \n",
       "3          NaN  ...   425972.0    5500767.0       7.7     NaN      NaN NaN   \n",
       "4          NaN  ...   133828.0     499849.0      26.8     NaN      NaN NaN   \n",
       "\n",
       "   RSE  CA_decile  CA_RR                   version  \n",
       "0  NaN        NaN    1.0  Tue Jun 12 12:05:41 2018  \n",
       "1  NaN        NaN    1.0  Tue Jun 12 12:05:41 2018  \n",
       "2  NaN        NaN    1.0  Tue Jun 12 12:05:41 2018  \n",
       "3  NaN        NaN    1.0  Tue Jun 12 12:05:41 2018  \n",
       "4  NaN        NaN    1.0  Tue Jun 12 12:05:41 2018  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ind_id', 'ind_definition', 'reportyear', 'race_eth_code',\n",
       "       'race_eth_name', 'geotype', 'geotypevalue', 'geoname', 'county_name',\n",
       "       'county_fips', 'region_name', 'region_code', 'strata_one_code',\n",
       "       'strata_one_name', 'strata_two_code', 'strata_two_name', 'numerator',\n",
       "       'denominator', 'estimate', 'LL_95CI', 'UL_95CI', 'SE', 'RSE',\n",
       "       'CA_decile', 'CA_RR', 'version'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ea.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.3       , 13.8       , 41.8       , ..., 33.69111273,\n",
       "       41.49287898, 38.17125743])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ea.estimate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import censusdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_census = censusdata.download(\"acs5\",2022, censusdata.censusgeo([('nation', '010')]),[\"010XX00US\",\"$8600000\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "\n",
    "dataset_name = \"arindam235/startup-investments-crunchbase\"\n",
    "\n",
    "destination_path_vc = \"../data/startup_VCs/\"\n",
    "\n",
    "# destination_path_gdp = \"../data/gdp/\"\n",
    "destination_path_hh_income = \"../data/household_income/\"\n",
    "destination_path_unicorn_startups = \"../data/unicorn-startups/\"\n",
    "destination_path_us_cities = \"../data/us_cities/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sergejnuss/united-states-cities-database\n"
     ]
    }
   ],
   "source": [
    "# # Download dataset\n",
    "# api.dataset_download_files(\"arindam235/startup-investments-crunchbase\", path=destination_path_vc, unzip=True,force=True)\n",
    "## api.dataset_download_files(\"luxoloshilofunde/life-expectancy-vs-gdp-19502018\", path=destination_path_gdp, unzip=True,force=True)\n",
    "# api.dataset_download_files(\"claygendron/us-household-income-by-zip-code-2021-2011\", path=destination_path_hh_income, unzip=True,force=True)\n",
    "# api.dataset_download_files(\"ramjasmaurya/unicorn-startups\", path=destination_path_unicorn_startups, unzip=True,force=True)\n",
    "api.dataset_download_files(\"sergejnuss/united-states-cities-database\", path=destination_path_us_cities, unzip=True,force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vc = pd.read_csv(os.path.join(destination_path_vc, \"investments_VC.csv\"),encoding=\"ISO-8859-1\")\n",
    "# df_gdp = pd.read_csv(os.path.join(destination_path_gdp, \"Life Expectancy vs GDP 1950-2018.csv\"),encoding=\"ISO-8859-1\")\n",
    "df_hhi = pd.read_csv(os.path.join(destination_path_hh_income, \"us_income_zipcode.csv\"),encoding=\"ISO-8859-1\")\n",
    "df_ucs = pd.read_csv(os.path.join(destination_path_unicorn_startups, \"unicorns till sep 2022.csv\"),encoding=\"ISO-8859-1\",parse_dates=[3])\n",
    "df_us_cities = pd.read_csv(os.path.join(destination_path_us_cities, \"uscities.csv\"),encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['permalink', 'name', 'homepage_url', 'category_list', ' market ',\n",
       "       ' funding_total_usd ', 'status', 'country_code', 'state_code', 'region',\n",
       "       'city', 'funding_rounds', 'founded_at', 'founded_month',\n",
       "       'founded_quarter', 'founded_year', 'first_funding_at',\n",
       "       'last_funding_at', 'seed', 'venture', 'equity_crowdfunding',\n",
       "       'undisclosed', 'convertible_note', 'debt_financing', 'angel', 'grant',\n",
       "       'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n",
       "       'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n",
       "       'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vc.columns\n",
    "vc_columns_to_drop = ['permalink','homepage_url','first_funding_at',\n",
    "       'last_funding_at', 'seed', 'venture', 'equity_crowdfunding',\n",
    "       'undisclosed', 'convertible_note', 'debt_financing', 'angel', 'grant',\n",
    "       'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n",
    "       'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n",
    "       'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H']\n",
    "df_vc.rename(columns={' market ':\"market\",' funding_total_usd ':\"funding_total_usd\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_cities['zips'] = df_us_cities.zips.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_cities = df_us_cities.drop([\"source\",\"military\",\"incorporated\",\"timezone\",\"ranking\",\"id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ucs['joined_date'] = pd.to_datetime(df_ucs['Date Joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_ucs.rename(columns={ df_ucs.columns[4]: \"city\" }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ucs = df_ucs[df_ucs.Country==\"United States\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ucs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Valuation ($B)</th>\n",
       "      <th>Date Joined</th>\n",
       "      <th>Country</th>\n",
       "      <th>CityÂ</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Investors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByteDance</td>\n",
       "      <td>$140</td>\n",
       "      <td>4/7/2017</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Artificial intelligence</td>\n",
       "      <td>Sequoia Capital China, SIG Asia Investments, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SpaceX</td>\n",
       "      <td>$127</td>\n",
       "      <td>12/1/2012</td>\n",
       "      <td>United States</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Other</td>\n",
       "      <td>Founders Fund, Draper Fisher Jurvetson, Rothen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHEIN</td>\n",
       "      <td>$100</td>\n",
       "      <td>7/3/2018</td>\n",
       "      <td>China</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>E-commerce &amp; direct-to-consumer</td>\n",
       "      <td>Tiger Global Management, Sequoia Capital China...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>$95</td>\n",
       "      <td>1/23/2014</td>\n",
       "      <td>United States</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>Khosla Ventures, LowercaseCapital, capitalG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canva</td>\n",
       "      <td>$40</td>\n",
       "      <td>1/8/2018</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Surry Hills</td>\n",
       "      <td>Internet software &amp; services</td>\n",
       "      <td>Sequoia Capital China, Blackbird Ventures, Mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company Valuation ($B) Date Joined        Country         CityÂ   \\\n",
       "0  ByteDance           $140    4/7/2017          China        Beijing   \n",
       "1     SpaceX           $127   12/1/2012  United States      Hawthorne   \n",
       "2      SHEIN           $100    7/3/2018          China       Shenzhen   \n",
       "3     Stripe            $95   1/23/2014  United States  San Francisco   \n",
       "4      Canva            $40    1/8/2018      Australia    Surry Hills   \n",
       "\n",
       "                          Industry  \\\n",
       "0          Artificial intelligence   \n",
       "1                            Other   \n",
       "2  E-commerce & direct-to-consumer   \n",
       "3                          Fintech   \n",
       "4     Internet software & services   \n",
       "\n",
       "                                           Investors  \n",
       "0  Sequoia Capital China, SIG Asia Investments, S...  \n",
       "1  Founders Fund, Draper Fisher Jurvetson, Rothen...  \n",
       "2  Tiger Global Management, Sequoia Capital China...  \n",
       "3        Khosla Ventures, LowercaseCapital, capitalG  \n",
       "4  Sequoia Capital China, Blackbird Ventures, Mat...  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ucs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhi_columns_to_drop = []\n",
    "for i in df_hhi.columns:\n",
    "    if \"Error\" in i:\n",
    "        hhi_columns_to_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hhi.drop(hhi_columns_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hhi = df_hhi[list(df_hhi.columns[:16]) + list(df_hhi.columns[-1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'Fintech', 'Supply chain, logistics, & delivery',\n",
       "       'Data management & analytics', 'E-commerce & direct-to-consumer',\n",
       "       'Internet software & services', 'Health',\n",
       "       'Artificial intelligence', 'Consumer & retail', 'Cybersecurity',\n",
       "       'Mobile & telecommunications', 'Auto & transportation', 'Travel',\n",
       "       'Hardware', 'Edtech', 'Artificial Intelligence'], dtype=object)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ucs.Industry.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>population</th>\n",
       "      <th>density</th>\n",
       "      <th>zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>72001</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>18.1638</td>\n",
       "      <td>-66.7235</td>\n",
       "      <td>4258</td>\n",
       "      <td>2192</td>\n",
       "      <td>[00601]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city city_ascii state_id   state_name  county_fips county_name  \\\n",
       "7329  Adjuntas   Adjuntas       PR  Puerto Rico        72001    Adjuntas   \n",
       "\n",
       "          lat      lng  population  density     zips  \n",
       "7329  18.1638 -66.7235        4258     2192  [00601]  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_us_cities[df_us_cities['zips'].apply(lambda x: isinstance(x, list) and \"00601\" in x if x is not None else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_cities_zip = df_us_cities.explode(\"zips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>population</th>\n",
       "      <th>density</th>\n",
       "      <th>zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>72001</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>18.1638</td>\n",
       "      <td>-66.7235</td>\n",
       "      <td>4258</td>\n",
       "      <td>2192</td>\n",
       "      <td>00601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city city_ascii state_id   state_name  county_fips county_name  \\\n",
       "7329  Adjuntas   Adjuntas       PR  Puerto Rico        72001    Adjuntas   \n",
       "\n",
       "          lat      lng  population  density   zips  \n",
       "7329  18.1638 -66.7235        4258     2192  00601  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_cities_zip[df_us_cities_zip['zips']==\"00601\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hhi.ZIP.apply(lambda x: str(x).zfill(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_hhi['zip_code'] = df_hhi.ZIP.astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_us_cities.city.unique()).intersection(set(df_ucs.city.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19090, 133)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_us_cities.city.unique()),len(df_ucs.city.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_cities=df_us_cities.iloc[df_us_cities.groupby('city')['population'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(df_ucs, df_us_cities, on='city', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"Investors\",\"Date Joined\"]\n",
    "\n",
    "final_df.drop(columns=columns_to_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Valuation ($B)</th>\n",
       "      <th>Country</th>\n",
       "      <th>city</th>\n",
       "      <th>Industry</th>\n",
       "      <th>founded_date</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>population</th>\n",
       "      <th>density</th>\n",
       "      <th>zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpaceX</td>\n",
       "      <td>$127</td>\n",
       "      <td>United States</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Other</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6037</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>33.9146</td>\n",
       "      <td>-118.3476</td>\n",
       "      <td>86068</td>\n",
       "      <td>5463</td>\n",
       "      <td>[90250, 90251, 90310]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epirus</td>\n",
       "      <td>$1.35</td>\n",
       "      <td>United States</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Other</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6037</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>33.9146</td>\n",
       "      <td>-118.3476</td>\n",
       "      <td>86068</td>\n",
       "      <td>5463</td>\n",
       "      <td>[90250, 90251, 90310]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>$95</td>\n",
       "      <td>United States</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6075</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>37.7562</td>\n",
       "      <td>-122.4430</td>\n",
       "      <td>3592294</td>\n",
       "      <td>7256</td>\n",
       "      <td>[94130, 94131, 94132, 94133, 94134, 94109, 941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Instacart</td>\n",
       "      <td>$39</td>\n",
       "      <td>United States</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Supply chain, logistics, &amp; delivery</td>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6075</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>37.7562</td>\n",
       "      <td>-122.4430</td>\n",
       "      <td>3592294</td>\n",
       "      <td>7256</td>\n",
       "      <td>[94130, 94131, 94132, 94133, 94134, 94109, 941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Databricks</td>\n",
       "      <td>$38</td>\n",
       "      <td>United States</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Data management &amp; analytics</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6075</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>37.7562</td>\n",
       "      <td>-122.4430</td>\n",
       "      <td>3592294</td>\n",
       "      <td>7256</td>\n",
       "      <td>[94130, 94131, 94132, 94133, 94134, 94109, 941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Tarana Wireless</td>\n",
       "      <td>$1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Milpitas</td>\n",
       "      <td>Mobile &amp; telecommunications</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>Milpitas</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6085</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>37.4339</td>\n",
       "      <td>-121.8921</td>\n",
       "      <td>84196</td>\n",
       "      <td>2381</td>\n",
       "      <td>[95035]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>Genies</td>\n",
       "      <td>$1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Venice</td>\n",
       "      <td>Internet software &amp; services</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>Venice</td>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>12115</td>\n",
       "      <td>Sarasota</td>\n",
       "      <td>27.1163</td>\n",
       "      <td>-82.4135</td>\n",
       "      <td>23985</td>\n",
       "      <td>614</td>\n",
       "      <td>[34285, 34292, 34275]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Divergent 3D</td>\n",
       "      <td>$1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Torrance</td>\n",
       "      <td>Auto &amp; transportation</td>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>Torrance</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6037</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>33.8346</td>\n",
       "      <td>-118.3417</td>\n",
       "      <td>143592</td>\n",
       "      <td>2701</td>\n",
       "      <td>[90277, 90501, 90503, 90505, 90504, 90507, 905...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>JupiterOne</td>\n",
       "      <td>$1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Morrisville</td>\n",
       "      <td>Cybersecurity</td>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>Morrisville</td>\n",
       "      <td>NC</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>37183</td>\n",
       "      <td>Wake</td>\n",
       "      <td>35.8367</td>\n",
       "      <td>-78.8348</td>\n",
       "      <td>28846</td>\n",
       "      <td>1277</td>\n",
       "      <td>[27560]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Unstoppable Domains</td>\n",
       "      <td>$1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Internet software &amp; services</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>32003</td>\n",
       "      <td>Clark</td>\n",
       "      <td>36.2333</td>\n",
       "      <td>-115.2654</td>\n",
       "      <td>2104198</td>\n",
       "      <td>1773</td>\n",
       "      <td>[89107, 89106, 89104, 89102, 89101, 89108, 891...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Valuation ($B)        Country           city  \\\n",
       "0                 SpaceX           $127  United States      Hawthorne   \n",
       "1                 Epirus          $1.35  United States      Hawthorne   \n",
       "2                 Stripe            $95  United States  San Francisco   \n",
       "3              Instacart            $39  United States  San Francisco   \n",
       "4             Databricks            $38  United States  San Francisco   \n",
       "..                   ...            ...            ...            ...   \n",
       "622      Tarana Wireless             $1  United States       Milpitas   \n",
       "623               Genies             $1  United States         Venice   \n",
       "624         Divergent 3D             $1  United States       Torrance   \n",
       "625           JupiterOne             $1  United States    Morrisville   \n",
       "626  Unstoppable Domains             $1  United States      Las Vegas   \n",
       "\n",
       "                                Industry founded_date     city_ascii state_id  \\\n",
       "0                                  Other   2012-12-01      Hawthorne       CA   \n",
       "1                                  Other   2022-02-14      Hawthorne       CA   \n",
       "2                                Fintech   2014-01-23  San Francisco       CA   \n",
       "3    Supply chain, logistics, & delivery   2014-12-30  San Francisco       CA   \n",
       "4            Data management & analytics   2019-02-05  San Francisco       CA   \n",
       "..                                   ...          ...            ...      ...   \n",
       "622          Mobile & telecommunications   2022-03-23       Milpitas       CA   \n",
       "623         Internet software & services   2022-04-12         Venice       FL   \n",
       "624                Auto & transportation   2022-04-25       Torrance       CA   \n",
       "625                        Cybersecurity   2022-06-02    Morrisville       NC   \n",
       "626         Internet software & services   2022-07-27      Las Vegas       NV   \n",
       "\n",
       "         state_name  county_fips    county_name      lat       lng  \\\n",
       "0        California         6037    Los Angeles  33.9146 -118.3476   \n",
       "1        California         6037    Los Angeles  33.9146 -118.3476   \n",
       "2        California         6075  San Francisco  37.7562 -122.4430   \n",
       "3        California         6075  San Francisco  37.7562 -122.4430   \n",
       "4        California         6075  San Francisco  37.7562 -122.4430   \n",
       "..              ...          ...            ...      ...       ...   \n",
       "622      California         6085    Santa Clara  37.4339 -121.8921   \n",
       "623         Florida        12115       Sarasota  27.1163  -82.4135   \n",
       "624      California         6037    Los Angeles  33.8346 -118.3417   \n",
       "625  North Carolina        37183           Wake  35.8367  -78.8348   \n",
       "626          Nevada        32003          Clark  36.2333 -115.2654   \n",
       "\n",
       "     population  density                                               zips  \n",
       "0         86068     5463                              [90250, 90251, 90310]  \n",
       "1         86068     5463                              [90250, 90251, 90310]  \n",
       "2       3592294     7256  [94130, 94131, 94132, 94133, 94134, 94109, 941...  \n",
       "3       3592294     7256  [94130, 94131, 94132, 94133, 94134, 94109, 941...  \n",
       "4       3592294     7256  [94130, 94131, 94132, 94133, 94134, 94109, 941...  \n",
       "..          ...      ...                                                ...  \n",
       "622       84196     2381                                            [95035]  \n",
       "623       23985      614                              [34285, 34292, 34275]  \n",
       "624      143592     2701  [90277, 90501, 90503, 90505, 90504, 90507, 905...  \n",
       "625       28846     1277                                            [27560]  \n",
       "626     2104198     1773  [89107, 89106, 89104, 89102, 89101, 89108, 891...  \n",
       "\n",
       "[627 rows x 16 columns]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hhi.drop(columns=[\"ZIP\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_exploded = final_df.explode('zips').rename(columns={'zips': 'zip_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = df_hhi.merge(final_df_exploded, on='zip_code', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_city_hhi_vc = merged_df.groupby(\"Company\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_city_hhi_vc = final_merged_city_hhi_vc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Households</th>\n",
       "      <th>Households Less Than $10,000</th>\n",
       "      <th>Households $10,000 to $14,999</th>\n",
       "      <th>Households $15,000 to $24,999</th>\n",
       "      <th>Households $25,000 to $34,999</th>\n",
       "      <th>Households $35,000 to $49,999</th>\n",
       "      <th>Households $50,000 to $74,999</th>\n",
       "      <th>Households $75,000 to $99,999</th>\n",
       "      <th>Households $100,000 to $149,999</th>\n",
       "      <th>Households $150,000 to $199,999</th>\n",
       "      <th>Households $200,000 or More</th>\n",
       "      <th>Households Median Income (Dollars)</th>\n",
       "      <th>Households Mean Income (Dollars)</th>\n",
       "      <th>Year</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>population</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.00000</td>\n",
       "      <td>625.0</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>6.250000e+02</td>\n",
       "      <td>625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14008.745600</td>\n",
       "      <td>5.871200</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>6.020640</td>\n",
       "      <td>5.322880</td>\n",
       "      <td>8.228000</td>\n",
       "      <td>12.161600</td>\n",
       "      <td>9.608160</td>\n",
       "      <td>15.048800</td>\n",
       "      <td>9.813600</td>\n",
       "      <td>21.648640</td>\n",
       "      <td>97927.641600</td>\n",
       "      <td>151869.41280</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>18553.889600</td>\n",
       "      <td>38.199574</td>\n",
       "      <td>-103.517764</td>\n",
       "      <td>5.348962e+06</td>\n",
       "      <td>5373.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6243.311965</td>\n",
       "      <td>3.098682</td>\n",
       "      <td>5.383784</td>\n",
       "      <td>3.054144</td>\n",
       "      <td>2.913151</td>\n",
       "      <td>3.386796</td>\n",
       "      <td>4.085367</td>\n",
       "      <td>3.031065</td>\n",
       "      <td>3.419927</td>\n",
       "      <td>3.058446</td>\n",
       "      <td>13.536627</td>\n",
       "      <td>49014.974765</td>\n",
       "      <td>76291.30976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15667.238197</td>\n",
       "      <td>3.529168</td>\n",
       "      <td>21.743809</td>\n",
       "      <td>6.640189e+06</td>\n",
       "      <td>3554.892624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21180.000000</td>\n",
       "      <td>45103.00000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>4013.000000</td>\n",
       "      <td>25.539600</td>\n",
       "      <td>-122.650000</td>\n",
       "      <td>4.340000e+02</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9685.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>55888.000000</td>\n",
       "      <td>104087.00000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>6075.000000</td>\n",
       "      <td>37.400000</td>\n",
       "      <td>-122.443000</td>\n",
       "      <td>1.243450e+05</td>\n",
       "      <td>1792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14273.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>100771.000000</td>\n",
       "      <td>134321.00000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>6085.000000</td>\n",
       "      <td>37.756200</td>\n",
       "      <td>-118.406800</td>\n",
       "      <td>3.592294e+06</td>\n",
       "      <td>5532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19213.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>110536.000000</td>\n",
       "      <td>170154.00000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>36061.000000</td>\n",
       "      <td>40.694300</td>\n",
       "      <td>-74.027900</td>\n",
       "      <td>5.449398e+06</td>\n",
       "      <td>7256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37699.000000</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>20.700000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>61.200000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>508208.00000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>55025.000000</td>\n",
       "      <td>48.754300</td>\n",
       "      <td>-71.018300</td>\n",
       "      <td>1.871322e+07</td>\n",
       "      <td>16268.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Households  Households Less Than $10,000  \\\n",
       "count    625.000000                    625.000000   \n",
       "mean   14008.745600                      5.871200   \n",
       "std     6243.311965                      3.098682   \n",
       "min        0.000000                      0.000000   \n",
       "25%     9685.000000                      3.300000   \n",
       "50%    14273.000000                      7.200000   \n",
       "75%    19213.000000                      7.500000   \n",
       "max    37699.000000                     26.100000   \n",
       "\n",
       "       Households $10,000 to $14,999  Households $15,000 to $24,999  \\\n",
       "count                     625.000000                     625.000000   \n",
       "mean                        6.300000                       6.020640   \n",
       "std                         5.383784                       3.054144   \n",
       "min                         0.000000                       0.600000   \n",
       "25%                         2.000000                       3.900000   \n",
       "50%                         3.400000                       5.400000   \n",
       "75%                        14.500000                       8.900000   \n",
       "max                        16.100000                      18.600000   \n",
       "\n",
       "       Households $25,000 to $34,999  Households $35,000 to $49,999  \\\n",
       "count                     625.000000                     625.000000   \n",
       "mean                        5.322880                       8.228000   \n",
       "std                         2.913151                       3.386796   \n",
       "min                         1.300000                       0.000000   \n",
       "25%                         3.300000                       6.500000   \n",
       "50%                         5.200000                       8.400000   \n",
       "75%                         6.500000                       9.200000   \n",
       "max                        28.800000                      20.700000   \n",
       "\n",
       "       Households $50,000 to $74,999  Households $75,000 to $99,999  \\\n",
       "count                     625.000000                     625.000000   \n",
       "mean                       12.161600                       9.608160   \n",
       "std                         4.085367                       3.031065   \n",
       "min                         0.000000                       3.900000   \n",
       "25%                        11.200000                       7.400000   \n",
       "50%                        11.600000                       9.400000   \n",
       "75%                        12.900000                      11.200000   \n",
       "max                        27.800000                      18.800000   \n",
       "\n",
       "       Households $100,000 to $149,999  Households $150,000 to $199,999  \\\n",
       "count                       625.000000                       625.000000   \n",
       "mean                         15.048800                         9.813600   \n",
       "std                           3.419927                         3.058446   \n",
       "min                           3.400000                         0.000000   \n",
       "25%                          12.300000                         8.100000   \n",
       "50%                          14.900000                        10.300000   \n",
       "75%                          16.900000                        11.500000   \n",
       "max                          30.800000                        27.600000   \n",
       "\n",
       "       Households $200,000 or More  Households Median Income (Dollars)  \\\n",
       "count                   625.000000                          625.000000   \n",
       "mean                     21.648640                        97927.641600   \n",
       "std                      13.536627                        49014.974765   \n",
       "min                       0.000000                        21180.000000   \n",
       "25%                      14.100000                        55888.000000   \n",
       "50%                      19.300000                       100771.000000   \n",
       "75%                      25.200000                       110536.000000   \n",
       "max                      61.200000                       250000.000000   \n",
       "\n",
       "       Households Mean Income (Dollars)    Year   county_fips         lat  \\\n",
       "count                         625.00000   625.0    625.000000  625.000000   \n",
       "mean                       151869.41280  2021.0  18553.889600   38.199574   \n",
       "std                         76291.30976     0.0  15667.238197    3.529168   \n",
       "min                         45103.00000  2021.0   4013.000000   25.539600   \n",
       "25%                        104087.00000  2021.0   6075.000000   37.400000   \n",
       "50%                        134321.00000  2021.0   6085.000000   37.756200   \n",
       "75%                        170154.00000  2021.0  36061.000000   40.694300   \n",
       "max                        508208.00000  2021.0  55025.000000   48.754300   \n",
       "\n",
       "              lng    population       density  \n",
       "count  625.000000  6.250000e+02    625.000000  \n",
       "mean  -103.517764  5.348962e+06   5373.150400  \n",
       "std     21.743809  6.640189e+06   3554.892624  \n",
       "min   -122.650000  4.340000e+02     78.000000  \n",
       "25%   -122.443000  1.243450e+05   1792.000000  \n",
       "50%   -118.406800  3.592294e+06   5532.000000  \n",
       "75%    -74.027900  5.449398e+06   7256.000000  \n",
       "max    -71.018300  1.871322e+07  16268.000000  "
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_city_hhi_vc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_city_hhi_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hhi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final ETL Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/arindam235/startup-investments-crunchbase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:09:54,716 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /kaggle-data-sets/517018/952128/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20241114%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20241114T120954Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=9fa0734701285277144163ab479d2a53dd6d92ae84aef9901b346fed6ce2ef137aae7dea687d83d8a46f85ba06e32c87b980728838ff6f83f25ea2674e43f7882a714f8baac0779527c452dc6a8daeadb995e6aeff0f4b8fd4d12cc34c78af0f123f8666c2c86676970bf950788bc3eea67a0e155a7c81723cd2c9176b50f289c2fe2a056fa3f3d181864eecd7c0972085423e099e4ca1d0f2981e41148dec827d99d9644df50dd789a6932419764b65e49c2a3998f1b1073ab36b633212a953a72cad4e4b391be4a6ad7c7134b7621e79c3249aa7b6b994e4df864167571688c072731f59a882c19a3204faf0306aeb6a7c33d42fa6043e150ee0494bf4d18c\n",
      "2024-11-14 13:09:54,716 - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /kaggle-data-sets/517018/952128/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20241114%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20241114T120954Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=9fa0734701285277144163ab479d2a53dd6d92ae84aef9901b346fed6ce2ef137aae7dea687d83d8a46f85ba06e32c87b980728838ff6f83f25ea2674e43f7882a714f8baac0779527c452dc6a8daeadb995e6aeff0f4b8fd4d12cc34c78af0f123f8666c2c86676970bf950788bc3eea67a0e155a7c81723cd2c9176b50f289c2fe2a056fa3f3d181864eecd7c0972085423e099e4ca1d0f2981e41148dec827d99d9644df50dd789a6932419764b65e49c2a3998f1b1073ab36b633212a953a72cad4e4b391be4a6ad7c7134b7621e79c3249aa7b6b994e4df864167571688c072731f59a882c19a3204faf0306aeb6a7c33d42fa6043e150ee0494bf4d18c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/claygendron/us-household-income-by-zip-code-2021-2011\n",
      "Dataset URL: https://www.kaggle.com/datasets/ramjasmaurya/unicorn-startups\n",
      "Dataset URL: https://www.kaggle.com/datasets/sergejnuss/united-states-cities-database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:10:14,986 - INFO - Successfully downloaded data files\n",
      "2024-11-14 13:10:19,167 - INFO - Successfully created dataframes from files\n",
      "2024-11-14 13:10:19,167 - INFO - Removing the temporary files and folders\n",
      "2024-11-14 13:10:19,170 - INFO - Successfully removed temporary source files\n",
      "2024-11-14 13:10:19,184 - INFO - Successfully removed temporary source files\n",
      "2024-11-14 13:10:19,185 - INFO - Successfully removed temporary source files\n",
      "2024-11-14 13:10:19,187 - INFO - Successfully removed temporary source files\n",
      "2024-11-14 13:10:19,188 - INFO - Extraction completed.\n",
      "C:\\Users\\Chris\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Chris\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "2024-11-14 13:10:21,308 - INFO - Transformation completed.\n",
      "2024-11-14 13:10:21,334 - INFO - ETL process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class ETLPipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.datasets = [\n",
    "            \"arindam235/startup-investments-crunchbase\",\n",
    "            \"claygendron/us-household-income-by-zip-code-2021-2011\",\n",
    "            \"ramjasmaurya/unicorn-startups\",\n",
    "            \"sergejnuss/united-states-cities-database\"\n",
    "        ]\n",
    "\n",
    "        self.source_file_paths = [\n",
    "         \"../data/startup_VCs/\",\n",
    "         \"../data/household_income/\",\n",
    "         \"../data/unicorn-startups/\",\n",
    "         \"../data/us_cities/\"]\n",
    "        \n",
    "        self.kaggle_encoding = \"ISO-8859-1\"\n",
    "        self.csv_names = [  \"investments_VC.csv\",\n",
    "                            \"us_income_zipcode.csv\",\n",
    "                            \"unicorns till sep 2022.csv\",\n",
    "                            \"uscities.csv\",\n",
    "                         ]\n",
    "\n",
    "        self.final_data_file_name = \"startups_household_income_metropolitan_area.csv\"\n",
    "        \n",
    "\n",
    "    def extract(self,del_tmp_files):\n",
    "        \"\"\"Extract data from online sources/apis in dataframe and return pandas dataframes for each file\"\"\"\n",
    "        try:\n",
    "            api = KaggleApi()\n",
    "            # Download the dataset from Kaggle\n",
    "            for i,dataset in enumerate(self.datasets):\n",
    "                try:\n",
    "                    api.dataset_download_files(self.datasets[i], path=self.source_file_paths[i], unzip=True,force=True)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Failed to download data from {dataset}: {e}\")\n",
    "                    raise\n",
    "            logging.info(f\"Successfully downloaded data files\")\n",
    "            \n",
    "            dfs = []\n",
    "            for i,dataset in enumerate(self.datasets):\n",
    "                try:\n",
    "                    dfs.append(pd.read_csv(os.path.join(self.source_file_paths[i], self.csv_names[i]),encoding=self.kaggle_encoding))\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Failed to create dataframe for {self.csv_names[i]}: {e}\")\n",
    "                    raise\n",
    "            logging.info(f\"Successfully created dataframes from files\")\n",
    "            \n",
    "            \n",
    "            # Cleanup temporary files and folders after loading the data in dataframes\n",
    "            if del_tmp_files:\n",
    "                logging.info(f\"Removing the temporary files and folders\")\n",
    "                for i,dataset in enumerate(self.source_file_paths):\n",
    "                    # Remove the raw csv files\n",
    "                    try:\n",
    "                        os.remove(os.path.join(self.source_file_paths[i], self.csv_names[i]))\n",
    "                        os.rmdir(self.source_file_paths[i])\n",
    "                        logging.info(f\"Successfully removed temporary source file: {os.path.join(self.source_file_paths[i], self.csv_names[i])}\")\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Failed to remove temporary file {os.path.join(self.source_file_paths[i], self.csv_names[i])}: {e}\")\n",
    "            \n",
    "            df_vc, df_hhi, df_ucs, df_us_cities = dfs[0],dfs[1],dfs[2],dfs[3]\n",
    "            return df_vc, df_hhi, df_ucs, df_us_cities\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred during extraction: {e}\")\n",
    "            raise\n",
    "\n",
    "    def transform(self, df_vc, df_hhi, df_ucs, df_us_cities):\n",
    "        \"\"\"Apply df specific transformations on dataframe and join them\"\"\"\n",
    "        try:\n",
    "            \n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # DataSource-1: VC data\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            try:\n",
    "                vc_columns_to_drop = ['permalink','homepage_url','first_funding_at',\n",
    "                                   'last_funding_at', 'seed', 'venture', 'equity_crowdfunding',\n",
    "                                   'undisclosed', 'convertible_note', 'debt_financing', 'angel', 'grant',\n",
    "                                   'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n",
    "                                   'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n",
    "                                   'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H']\n",
    "                df_vc.rename(columns={' market ':\"market\",' funding_total_usd ':\"funding_total_usd\"},inplace=True)\n",
    "                df_vc.drop(vc_columns_to_drop,inplace=True,axis=1)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to transform 'VC' data: {e}\")\n",
    "            \n",
    "            \n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # DataSource-2: US household_income data\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            try:\n",
    "                hhi_columns_to_drop = []\n",
    "                for i in df_hhi.columns:\n",
    "                    if \"Error\" in i:\n",
    "                        hhi_columns_to_drop.append(i)\n",
    "\n",
    "                df_hhi.drop(hhi_columns_to_drop,axis=1,inplace=True)\n",
    "\n",
    "                df_hhi = df_hhi[list(df_hhi.columns[:16]) + list(df_hhi.columns[-1:])]\n",
    "                # df_hhi['zip_code'] = df_hhi.ZIP.astype(str).str.zfill(5)\n",
    "                df_hhi['zip_code'] = df_hhi.ZIP.apply(lambda x: str(x).zfill(5))\n",
    "                df_hhi.drop(columns=[\"ZIP\"],inplace=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to transform 'Household Income' data: {e}\")\n",
    "                              \n",
    "            \n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # DataSource-3: US unicorn startups data\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "                              \n",
    "            try:\n",
    "                ucs_columns_to_drop = [\"Investors\",\"Date Joined\"]\n",
    "                df_ucs = df_ucs[df_ucs.Country==\"United States\"]\n",
    "                df_ucs['joined_date'] = pd.to_datetime(df_ucs['Date Joined'])\n",
    "                df_ucs.rename(columns={ df_ucs.columns[4]: \"city\" }, inplace = True)\n",
    "                df_ucs.drop(columns=ucs_columns_to_drop,inplace=True)\n",
    "                df_ucs.reset_index(drop=True, inplace=True)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to transform 'US unicorn startups' data: {e}\")\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # DataSource-4: US cities database\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "            try:\n",
    "                us_cities_columns_to_drop = [\"source\",\"military\",\"incorporated\",\"timezone\",\"ranking\",\"id\"]\n",
    "                df_us_cities['zips'] = df_us_cities.zips.str.split()\n",
    "                df_us_cities = df_us_cities.drop(us_cities_columns_to_drop,axis=1)\n",
    "                ## city name is not unique and can have multiple instances in US so for joining it with other \n",
    "                ## have to select most populated one.\n",
    "                df_us_cities=df_us_cities.iloc[df_us_cities.groupby('city')['population'].idxmax()]\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to transform 'US cities' data: {e}\")                              \n",
    "                              \n",
    "            # ----------------------------------------------------------------------------------------\n",
    "            # Transformation --> Merging DataSource-3 & DataSource-4 to combine regional and population related details\n",
    "            transformed_df_ucs_us_cities = pd.merge(df_ucs, df_us_cities, on='city', how='inner')\n",
    "            transformed_df_ucs_us_cities = transformed_df_ucs_us_cities.explode('zips').rename(columns={'zips': 'zip_code'})\n",
    "            \n",
    "            # Transformation --> Merging DataSource-2 & cities transformed data to add US houesehold income details with metropolitan area mapping\n",
    "            transformed_df = df_hhi.merge(transformed_df_ucs_us_cities, on='zip_code', how='inner')\n",
    "            # Due to exploding of cities dataframe with zip codes there is duplication in data. To remove duplication:\n",
    "            transformed_df = transformed_df.groupby(\"Company\").first()\n",
    "\n",
    "            transformed_df = transformed_df.reset_index()\n",
    "\n",
    "            # transformed_city_hhi_vc.describe()\n",
    "\n",
    "            return transformed_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred during transformation: {e}\")\n",
    "            raise\n",
    "\n",
    "    def load(self, transformed_df, destination_path):\n",
    "        try:\n",
    "\n",
    "            final_file_path = os.path.join(destination_path,self.final_data_file_name)\n",
    "            transformed_df.to_csv(final_file_path,index=False)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while writing df to file: {e}\")\n",
    "            raise\n",
    "\n",
    "        return None           \n",
    "            \n",
    "        \n",
    "    def run(self,del_tmp_files=False):\n",
    "        try:\n",
    "            df_vc, df_hhi, df_ucs, df_us_cities = self.extract(del_tmp_files)\n",
    "            logging.info(\"Extraction completed.\")\n",
    "            \n",
    "            transformed_df = self.transform(df_vc, df_hhi, df_ucs, df_us_cities)\n",
    "            logging.info(\"Transformation completed.\")\n",
    "                              \n",
    "            transformed_data_destination = os.path.join(os.path.split(os.getcwd())[0],\"data\")\n",
    "            self.load(transformed_df, transformed_data_destination)\n",
    "            logging.info(\"ETL process completed successfully.\")\n",
    "            return transformed_df\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred during the ETL process: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# Running the ETL pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    etl = ETLPipeline()\n",
    "    transformed_df = etl.run(del_tmp_files=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
